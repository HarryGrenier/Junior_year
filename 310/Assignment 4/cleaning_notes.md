# What are 3 common problems to look for in a dataset? Describe them with examples.
## Missing Values:
	consider a data set that stores patients information at a hospital there is a chance that there might be missing information about some patients such as missing hight/weight or medical insurance information. This could be cause by a variation of things for example if the patient doesnt have insurance or even if the hospital did have a need for getting the height and weight and just got lazy. This can be prevented by deleting those rows, imputing them with the mean, median, or mode along with other options.
## Outliers
	This are bits of data that dont follow the rest of the data where maybe most of the data is in one range then you have one value thats 10 times that. An example of this could be houses in a certin area say most houses are in the 100-500k range then you have a few houses in the millions say 10 million + this would be an example or an outlier. This can be worked with by picking them out with standard deviation, or visual methods like box plots. Once discovered, you can decide whether to remove them, cap/floor them, or analyze them separately.
## Inconsistencies and Errors
	Inconsistencies or errors can be caused from issues in data collection, transcription errors, or other reasons. An example of this would be possibly in dataset that logs travel details, the 'Country' column might have differnt entries for the United States like 'USA', 'U.S.A', 'United States', 'US', etc. This could be problematic when trying to sort by these countrys and you arnt able to get consistant results. This issue can be fixed by standardizing the data by using a single consistent format such as changing them all to "USA".
# Part 2:
	An example of these issues seen in the data that I just cleaned would be missing values and Inconsistancies. I started cleaning this data by removing all the columns that had more then 50% of the rows with missing data. That then left me with just the id of the caribou,sex,study site, location (longitude and latitude), and deploy_off_type (What happened to the tracker). Once this data was left it was already alot clearer but there was still a large chunk of data missing in the location. This is when I noticed that the study sites all had the same relitive location for where the caribou were tagged. So I then grouped all the data for the study sites and calcuated the average location between these sightes and filled the non existing loctions with this data. though this isnt helpful for every case for me it was helpful to have all of that filled in. In order to figure out where each of these caribou were it was important to have a location tied to them for my scatter plot. For I was looking to how the research site vary in location for each individual caribou and how consitrated they are in paticular areas. This helped me see what groups had more caribou in there sites.
# part 3
	Domain expertise is important in the data cleaning process as it allows individuals to make smart decisions about how to handle differnt data issues, ensuring the resulting dataset is not only clean but also meaningful and accurate for analysis in the specific area. Reading about this I found that there was a common trened in the medical examples so thats what im going to talk about. Consider a pharmaceutical company conduction clinical trials for a new drug. During exploring the data the data analyst notices some patients with cholesterol levels recorded as below 100 mg/dL and above 300 mg/dL. In general, cholesterol levels for adults are usually between 125 to 200 mg/dL. Someone without medical expertise might consider all values outside the typical range as errors or outliers and might delete or alter these records. However, a domain expert would uderstands that Low Cholesterol might have been on cholesterol-lowering medications, or they might have specific health conditions that result in low cholesterol levels. where as with high it's possible for individuals to have significantly elevated cholesterol levels due to genetic conditions or severe lifestyle factors. In this example without the domain expertise you could misshandle the data and alter important information which could lead to inaccurate analyses and potentially misguided conclusions about the drug's safety or effecency.